/**
 * å®Œæ•´æµ‹è¯• AI æœåŠ¡æµç¨‹
 */

require('dotenv').config();
const { ChatOpenAI } = require('@langchain/openai');

console.log('ğŸ” å®Œæ•´æµ‹è¯• AI æœåŠ¡æµç¨‹...\n');

const API_KEY = process.env.GROQ_API_KEY;
const BASE_URL = process.env.GROQ_BASE_URL;
const MODEL = process.env.GROQ_MODEL;

console.log('ğŸ“‹ ç¯å¢ƒå˜é‡:');
console.log(`   GROQ_API_KEY: ${API_KEY ? 'âœ… å·²è®¾ç½®' : 'âŒ æœªè®¾ç½®'}`);
console.log(`   GROQ_BASE_URL: ${BASE_URL || 'âŒ æœªè®¾ç½®'}`);
console.log(`   GROQ_MODEL: ${MODEL || 'âŒ æœªè®¾ç½®'}\n`);

if (!API_KEY || !BASE_URL || !MODEL) {
  console.error('âŒ ç¯å¢ƒå˜é‡æœªæ­£ç¡®é…ç½®ï¼');
  process.exit(1);
}

async function testFullFlow() {
  try {
    console.log('1ï¸âƒ£ åˆå§‹åŒ– LLM Client...');
    
    const model = new ChatOpenAI({
      apiKey: API_KEY,
      model: MODEL,
      streaming: true,
      temperature: 0.7,
      configuration: {
        baseURL: BASE_URL,
      },
      maxRetries: 2,
      timeout: 30000,
    });
    
    console.log('   âœ… LLM Client åˆå§‹åŒ–æˆåŠŸ\n');
    
    console.log('2ï¸âƒ£ æµ‹è¯•æµå¼å“åº”...');
    const prompt = 'ä½ æ˜¯è°?';
    console.log(`   æç¤ºè¯: "${prompt}"`);
    console.log('   å“åº”: ');
    
    const stream = await model.stream(prompt);
    
    let fullResponse = '';
    let chunkCount = 0;
    const startTime = Date.now();
    
    for await (const chunk of stream) {
      const content = chunk.content;
      if (content && typeof content === 'string') {
        process.stdout.write(content);
        fullResponse += content;
        chunkCount++;
      }
    }
    
    const duration = Date.now() - startTime;
    
    console.log('\n');
    console.log(`   âœ… æµå¼å“åº”å®Œæˆ`);
    console.log(`   ğŸ“Š ç»Ÿè®¡: ${chunkCount} ä¸ªå—, ${fullResponse.length} å­—ç¬¦, ${duration}ms\n`);
    
    console.log('3ï¸âƒ£ æµ‹è¯•é”™è¯¯å¤„ç†...');
    try {
      const errorModel = new ChatOpenAI({
        apiKey: 'invalid-key',
        model: MODEL,
        streaming: true,
        configuration: {
          baseURL: BASE_URL,
        },
        maxRetries: 1,
        timeout: 5000,
      });
      
      await errorModel.invoke('test');
      console.log('   âš ï¸  åº”è¯¥æŠ›å‡ºé”™è¯¯ä½†æ²¡æœ‰\n');
    } catch (error) {
      console.log(`   âœ… é”™è¯¯å¤„ç†æ­£å¸¸: ${error.message}\n`);
    }
    
    console.log('ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼AI æœåŠ¡åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œã€‚\n');
    console.log('ğŸ’¡ å¦‚æœåç«¯è¿˜æ˜¯æŠ¥é”™ï¼Œè¯·æ£€æŸ¥:');
    console.log('   1. åç«¯æœåŠ¡æ˜¯å¦å·²é‡å¯');
    console.log('   2. åç«¯æ—¥å¿—ä¸­çš„å…·ä½“é”™è¯¯ä¿¡æ¯');
    console.log('   3. æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸');
    
  } catch (error) {
    console.error('\nâŒ æµ‹è¯•å¤±è´¥:');
    console.error(`   é”™è¯¯ç±»å‹: ${error.constructor.name}`);
    console.error(`   é”™è¯¯ä¿¡æ¯: ${error.message}`);
    
    if (error.response) {
      console.error(`   å“åº”çŠ¶æ€: ${error.response.status}`);
      console.error(`   å“åº”æ•°æ®: ${JSON.stringify(error.response.data)}`);
    }
    
    console.error(`\n   å †æ ˆ: ${error.stack}`);
    process.exit(1);
  }
}

testFullFlow();
