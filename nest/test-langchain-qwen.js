/**
 * æµ‹è¯• LangChain ä¸é€šä¹‰åƒé—®é›†æˆ
 */

require('dotenv').config();
const { ChatOpenAI } = require('@langchain/openai');

console.log('ğŸ” æµ‹è¯• LangChain ä¸é€šä¹‰åƒé—®é›†æˆ...\n');

const API_KEY = process.env.GROQ_API_KEY || 'sk-05c31220158d49cea02ce2b544c91288';
const BASE_URL = process.env.GROQ_BASE_URL || 'https://dashscope.aliyuncs.com/compatible-mode/v1';
const MODEL = process.env.GROQ_MODEL || 'qwen-plus';

console.log('ğŸ“‹ é…ç½®ä¿¡æ¯:');
console.log(`   API Key: ${API_KEY.substring(0, 20)}...`);
console.log(`   Base URL: ${BASE_URL}`);
console.log(`   Model: ${MODEL}\n`);

async function testLangChain() {
  try {
    console.log('ğŸš€ åˆå§‹åŒ– ChatOpenAI...');
    
    const model = new ChatOpenAI({
      apiKey: API_KEY,
      model: MODEL,
      streaming: false,
      temperature: 0.7,
      configuration: {
        baseURL: BASE_URL,
      },
      maxRetries: 2,
      timeout: 30000,
    });

    console.log('âœ… ChatOpenAI åˆå§‹åŒ–æˆåŠŸ\n');
    console.log('ğŸ“¤ å‘é€æµ‹è¯•æ¶ˆæ¯...');
    
    const response = await model.invoke('ä½ å¥½ï¼Œè¯·å›å¤"LangChain é›†æˆæµ‹è¯•æˆåŠŸ"');
    
    console.log('âœ… æ”¶åˆ°å“åº”ï¼\n');
    console.log('ğŸ“ AI å“åº”:');
    console.log(`   ${response.content}\n`);
    console.log('ğŸ‰ LangChain ä¸é€šä¹‰åƒé—®é›†æˆæˆåŠŸï¼');
    
  } catch (error) {
    console.error('âŒ æµ‹è¯•å¤±è´¥:');
    console.error(`   é”™è¯¯: ${error.message}`);
    console.error(`   è¯¦æƒ…: ${error.stack}\n`);
    
    if (error.message.includes('401')) {
      console.log('ğŸ’¡ API Key æ— æ•ˆ');
    } else if (error.message.includes('403')) {
      console.log('ğŸ’¡ API Key æƒé™ä¸è¶³');
    } else if (error.message.includes('timeout')) {
      console.log('ğŸ’¡ è¯·æ±‚è¶…æ—¶');
    }
    
    process.exit(1);
  }
}

testLangChain();
